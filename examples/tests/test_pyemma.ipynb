{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyEmma Featurizer Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import openpathsampling as paths\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! lazy\n",
    "import pyemma.coordinates as coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-12-16 15:02:03 openpathsampling.netcdfplus.netcdfplus INFO     Open existing netCDF file 'engine_store_test.nc' for reading - reading from existing file\n",
      "13-12-16 15:02:03 openpathsampling.netcdfplus.stores.variable INFO     Creates VariableStore with variables ['replica', 'trajectory', 'ensemble', 'bias', 'parent', 'mover'] and instatiated with ['replica', 'trajectory', 'ensemble', 'bias', 'parent', 'mover']\n",
      "13-12-16 15:02:03 openpathsampling.netcdfplus.stores.variable INFO     Creates VariableStore with variables ['samples', 'movepath'] and instatiated with ['samples', 'movepath']\n",
      "13-12-16 15:02:03 openpathsampling.netcdfplus.stores.variable INFO     Creates VariableStore with variables ['simulation', 'mccycle', 'previous', 'active', 'change'] and instatiated with ['simulation', 'mccycle', 'previous', 'active', 'change']\n",
      "13-12-16 15:02:03 openpathsampling.netcdfplus.util INFO     Ran load_indices in time 0.002149\n"
     ]
    }
   ],
   "source": [
    "#! lazy\n",
    "ref_storage = paths.Storage('engine_store_test.nc', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Create new netCDF file 'delete.nc' for writing - creating new file\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Setup netCDF file and create variables\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.stores.variable INFO     Creates VariableStore with variables ['replica', 'trajectory', 'ensemble', 'bias', 'parent', 'mover'] and instatiated with ['replica', 'trajectory', 'ensemble', 'bias', 'parent', 'mover']\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.stores.variable INFO     Creates VariableStore with variables ['samples', 'movepath'] and instatiated with ['samples', 'movepath']\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.stores.variable INFO     Creates VariableStore with variables ['simulation', 'mccycle', 'previous', 'active', 'change'] and instatiated with ['simulation', 'mccycle', 'previous', 'active', 'change']\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'trajectories'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'topologies'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'cvs'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'snapshots'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'samples'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'samplesets'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'movechanges'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'steps'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'details'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'pathmovers'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'shootingpointselectors'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'engines'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'pathsimulators'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'transitions'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'networks'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'schemes'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'interfacesets'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'msouters'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'volumes'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'ensembles'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'tag'\n",
      "13-12-16 15:02:05 openpathsampling.netcdfplus.netcdfplus INFO     Finished setting up netCDF file\n",
      "13-12-16 15:02:06 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'snapshot0'\n",
      "13-12-16 15:02:06 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'snapshot0statics'\n",
      "13-12-16 15:02:06 openpathsampling.netcdfplus.netcdfplus INFO     Initializing store 'snapshot0kinetics'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "221422574805173574613592029305145131028L"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! lazy\n",
    "storage = paths.Storage('delete.nc', 'w')\n",
    "storage.trajectories.save(ref_storage.trajectories[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import a PyEmma Coordinates Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using of pyemma featurizers or general other complex code requires a little trick to be storable. Since storing of code only works if we are not dependend on the context (scope) we need to wrap the construction of our featurizer in a function, that gets all it needs from the global scope as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pyemma_generator(f):\n",
    "    f.add_inverse_distances(f.pairs(f.select_Backbone()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = paths.collectivevariable.PyEMMAFeaturizerCV(\n",
    "    'pyemma', \n",
    "    pyemma_generator, \n",
    "    topology=ref_storage.snapshots[0].topology\n",
    ").with_diskcache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this featurizer generating function to build a collective variable out of it. All we need for that is a name as usual, the generating function, the list of parameters - here only the topology and at best a test snapshot, a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv(ref_storage.trajectories[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save it to the storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(store.cvs[CollectiveVariable] : 1 object(s), 2, 244452260558088618079842504778597793968L)\n"
     ]
    }
   ],
   "source": [
    "#! lazy\n",
    "print storage.save(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and apply the featurizer to a trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv(storage.trajectories[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sync to make sure the cache is written to the netCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv(storage.snapshots.all());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py_cv = storage.cvs['pyemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store = storage.stores['cv%d' % storage.idx(py_cv)]\n",
    "nc_var = store.variables['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "assert(nc_var.shape[1] == 15)\n",
    "print nc_var.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy.float32\n"
     ]
    }
   ],
   "source": [
    "assert(nc_var.var_type == 'numpy.float32')\n",
    "print nc_var.var_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ u'{\"_cls\":\"PyEMMAFeaturizerCV\",\"_dict\":{\"topology\":{\"_store\":\"topologies\",\"_hex_uuid\":\"0xa6946fccc13c11e68416000000000002L\"},\"name\":\"pyemma\",\"featurizer\":{\"_marshal\":\"YwEAAAABAAAAAwAAAEMAAABzIAAAAHwAAGoAAHwAAGoBAHwAAGoCAIMAAIMBAIMBAAFkAABTKAEAAABOKAMAAAB0FQAAAGFkZF9pbnZlcnNlX2Rpc3RhbmNlc3QFAAAAcGFpcnN0DwAAAHNlbGVjdF9CYWNrYm9uZSgBAAAAdAEAAABmKAAAAAAoAAAAAHMeAAAAPGlweXRob24taW5wdXQtNS00Nzc0ZDhlZGRkMDA+dBAAAABweWVtbWFfZ2VuZXJhdG9yAQAAAHMCAAAAAAE=\",\"_module_vars\":[],\"_global_vars\":[]},\"kwargs\":{}}}']\n"
     ]
    }
   ],
   "source": [
    "#! ignore\n",
    "print storage.variables['cvs_json'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "py_cv_idx = storage.idx(py_cv)\n",
    "print py_cv_idx\n",
    "py_emma_feat = storage.vars['cvs_json'][py_cv_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ReversalHashedList' object has no attribute 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-63f7c07d1a70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0merg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_emma_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnapshots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jan-hendrikprinz/Studium/git/openpathsampling/openpathsampling/chaindict.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0m__call__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jan-hendrikprinz/Studium/git/openpathsampling/openpathsampling/chaindict.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0m__call__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jan-hendrikprinz/Studium/git/openpathsampling/openpathsampling/chaindict.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;31m# turn possible iterators into a list if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jan-hendrikprinz/Studium/git/openpathsampling/openpathsampling/netcdfplus/stores/object.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \"\"\"\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# we want to iterator in the order object were saved!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0muuid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muuid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ReversalHashedList' object has no attribute 'list'"
     ]
    }
   ],
   "source": [
    "erg = py_emma_feat(storage.snapshots);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[221422574805173574613592029305145131020L,\n",
       " 221422574805173574613592029305145131040L,\n",
       " 221422574805173574613592029305145131046L,\n",
       " 221422574805173574613592029305145131052L,\n",
       " 221422574805173574613592029305145131058L,\n",
       " 221422574805173574613592029305145131064L,\n",
       " 221422574805173574613592029305145131070L,\n",
       " 221422574805173574613592029305145131076L,\n",
       " 221422574805173574613592029305145131082L,\n",
       " 221422574805173574613592029305145131088L]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.snapshots.index._list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.68972969  2.06547379]\n",
      " [ 2.61396885  2.00944018]\n",
      " [ 2.73087001  2.06900215]\n",
      " [ 2.79462361  2.09850192]]\n"
     ]
    }
   ],
   "source": [
    "#! lazy\n",
    "print erg[0::5,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "storage.close()\n",
    "ref_storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-08-16 13:18:54 openpathsampling.netcdfplus.netcdfplus INFO     Open existing netCDF file 'delete.nc' for reading - reading from existing file\n"
     ]
    }
   ],
   "source": [
    "#! lazy\n",
    "storage = paths.Storage('delete.nc', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = storage.cvs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that we get the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert np.allclose(erg, cv(storage.snapshots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
