{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import openpathsampling as paths\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import simtk.unit as u\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import psutil\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paths.base.StorableObject.observe_objects = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for caching of storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the template from a .pdb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmpl = paths.tools.snapshot_from_pdb('../data/Alanine_solvated.pdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a fresh storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = paths.storage.Storage('memtest.nc', template=tmpl, mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the caching mode to something that tries to cache only the very often used objects. It will actually remember the last 10 objects of each type and keep weak references to everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st.set_caching_mode('memtest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a random engine, which does only puts random numbers in the snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = paths.openmm_engine.OpenMMRandomEngine(template=tmpl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 4 ensembles of different lengths (everything else does not make sense with random snapshots), and create a random shooter for these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ens_list = [paths.LengthEnsemble(l) for l in [5,10,15,20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shooter = paths.RandomChoiceMover([\n",
    "        paths.OneWayShootingMover(ens, paths.UniformSelector()) for ens in ens_list\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate an initial global state of 4 trajectories of the correct length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_state = paths.SampleSet([\n",
    "    paths.Sample(\n",
    "        replica = repid,\n",
    "        trajectory = engine.generate(tmpl, [ens.can_append]),\n",
    "        ensemble = ens\n",
    "    )\n",
    "    for repid, ens in enumerate(ens_list)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check if all we did makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_state.consistency_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple simulator that will run the shooter from our initial state and store the results in the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simulation = paths.PathSampling(\n",
    "    storage = st,\n",
    "    engine = engine,\n",
    "    move_scheme = shooter,\n",
    "    globalstate = initial_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally run the simulator and watch the change in cached elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disc = psutil.disk_usage('.').free\n",
    "mem = psutil.virtual_memory().available\n",
    "store_size = os.stat('memtest.nc').st_size\n",
    "\n",
    "for i in range(500):    \n",
    "    disc_old = disc\n",
    "    mem_old = mem\n",
    "    simulation.run(1)    \n",
    "    disc = psutil.disk_usage('.').free\n",
    "    mem = psutil.virtual_memory().available    \n",
    "    store_size = os.stat('memtest.nc').st_size\n",
    "    info = {            \n",
    "            'disc' : (disc-disc_old) / 1024 / 10 ,\n",
    "            'file' : store_size / 1024 / 100,\n",
    "            'memory' : (mem-mem_old) / 1024 / 10,\n",
    "            'objects' : paths.base.StorableObject.count_weaks(),\n",
    "            'object_count' : len(paths.base.StorableObject._weak_cache)\n",
    "        }\n",
    "    image = st.cache_image()\n",
    "    info.update({key: value for key, value in image['weak'].iteritems() if st.objects[key].cache.size[1] != 0})\n",
    "    info['total'] = image['full']\n",
    "    info['image'] = image\n",
    "    data.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = len(data)\n",
    "dd = pd.DataFrame(data)\n",
    "zero_names = [name for name in data[0] if len([q for q in data if q[name] != data[0][name]]) == 0]\n",
    "ax = dd.plot(xlim=(-.4 * l,1.01 *l), ylim=(-1,201), figsize=(12,6.75), logy=True, y=\n",
    "        [name for name in data[0] \n",
    "         if name in st.objects and not name in zero_names and name != 'image' or name == 'object_count'],\n",
    "        title='Total # of stored objects present in memory summed by store')\n",
    "ax.set_xlabel(\"Iteration #\")\n",
    "ax.set_ylabel(\"# of Objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj_data = [d['objects'] for d in data]\n",
    "for n, d in enumerate(data):\n",
    "    obj_data[n]['total'] = d['object_count']\n",
    "l = len(obj_data)\n",
    "dd2 = pd.DataFrame(obj_data)\n",
    "# remove all columns that are strictly zero\n",
    "zero_names = [name for name in obj_data[0] if name != 'total' and len([q for q in obj_data if q[name] != obj_data[0][name]]) == 0]\n",
    "ax2 = dd2.plot(xlim=(-.4 * l,1.01 *l), ylim=(1,201), figsize=(12,6.75), logy=True, y=\n",
    "        [name for name in obj_data[0] if not name in zero_names],\n",
    "        title='Total # of objects in memory summed by base class (constant classes hidden)')\n",
    "ax2.set_xlabel(\"Iteration #\")\n",
    "ax2.set_ylabel(\"# of Objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tots = [d['image']['full'] for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very crude test. We assume that the total number of referenced object in the last 100 steps is not larger than the maximum before. This would fails if in the loops we would store stuff and still keep hidden references to these objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tots = [d['object_count'] for d in data]\n",
    "assert(max(tots[100:-100]) >= max(tots[-100:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we do not check is if we keep hidden references to objects that we do not explicitely store in memory. This could be a big problem although it is not related to our storage. It merely means the we somewhere keep hidden references to objects that whould have been disposed of, since we do not store them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = len(data)\n",
    "dd.plot(xlim=(-.4 * l,1.01 *l), ylim=(-1000,1000), figsize=(12,6.75), \n",
    "        y=[name for name in data[0] if name in ['memory'] and name != 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tots = [d['memory'] for d in data]\n",
    "print 'Average memory consummation per step %f MB [middle]' % (sum(tots[100:-100])/len(tots[100:-100]) * 10. / 1024.)\n",
    "print 'Average memory consummation per step %f MB [end]' % (sum(tots[-100:])/len(tots[-100:]) * 10. / 1024.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
