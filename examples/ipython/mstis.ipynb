{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running an MSTIS simulation\n",
    "\n",
    "Now we will use the initial trajectories we obtained from bootstrapping to run an MSTIS simulation. This will show both how objects can be regenerated from storage and how regenerated equivalent objects can be used in place of objects that weren't stored.\n",
    "\n",
    "Tasks covered in this notebook:\n",
    "* Loading OPS objects from storage\n",
    "* Ways of assigning initial trajectories to initial samples\n",
    "* Setting up a path sampling simulation with various move schemes\n",
    "* Visualizing trajectories while the path sampling is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "reload(logging)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import openpathsampling as paths\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading things from storage\n",
    "\n",
    "First we'll reload some of the stuff we stored before. Of course, this starts with opening the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_store = paths.AnalysisStorage(\"mstis_bootstrap.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of information can be recovered from the old storage, and so we don't have the recreate it. However, we did not save our network, so we'll have to create a new one. Since the network creates the ensembles, that means we will have to translate the trajectories from the old ensembles to new ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathMovers: 0\n",
      "Samples: 12\n",
      "Ensembles: 120\n",
      "SampleSets: 1\n",
      "Snapshots: 1742\n",
      "Networks: 0\n"
     ]
    }
   ],
   "source": [
    "print \"PathMovers:\", len(old_store.pathmovers)\n",
    "print \"Samples:\", len(old_store.samples)\n",
    "print \"Ensembles:\", len(old_store.ensembles)\n",
    "print \"SampleSets:\", len(old_store.samplesets)\n",
    "print \"Snapshots:\", len(old_store.snapshots)\n",
    "print \"Networks:\", len(old_store.networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading from storage is very easy. Each store is a list. We take the 0th snapshot as a template (it doesn't actually matter which one) for the next storage we'll create. There's only one engine stored, so we take the only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "template = old_store.snapshots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = old_store.engines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named objects can be found in storage using the `find` function. This allows us to load our old collective variables and states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opA = old_store.cvs['opA']\n",
    "opB = old_store.cvs['opB']\n",
    "opC = old_store.cvs['opC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stateA = old_store.volumes['A']\n",
    "stateB = old_store.volumes['B']\n",
    "stateC = old_store.volumes['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we could also load the interfaces, but it takes less code to build new ones:\n",
    "interfacesA = paths.VolumeFactory.CVRangeVolumeSet(opA, 0.0,[0.2**2, 0.3**2, 0.4**2, 0.5**2])\n",
    "interfacesB = paths.VolumeFactory.CVRangeVolumeSet(opB, 0.0,[0.2**2, 0.3**2, 0.4**2, 0.5**2])\n",
    "interfacesC = paths.VolumeFactory.CVRangeVolumeSet(opC, 0.0,[0.2**2, 0.3**2, 0.4**2, 0.5**2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we have everything we need to build the MSTIS network. Recall that this will create all the ensembles we need for the simulation. However, even though the ensembles are semantically the same, these are not the same objects. We'll need to deal with that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mstis = paths.MSTISNetwork([\n",
    "    (stateA, interfacesA, opA),\n",
    "    (stateB, interfacesB, opB),\n",
    "    (stateC, interfacesC, opC)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we need to set up real trajectories that we can use for each of these. We can start by loading the stored sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the sample set we have saved before\n",
    "old_sampleset = old_store.samplesets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About `Sample`s\n",
    "\n",
    "The OPS object called `Sample` is used to associate a trajectory with a replica ID and an ensemble. The trajectory needs to be associated with an ensemble so we know how to get correct statistics from the many ensembles that we might be sampling simultaneously. The trajectory needs to be associated with a replica ID so that replica exchange approaches can be analyzed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ensembles in our MSTIS network are not the exact ensemble objects that we saved our samples with (they were rebuilt), we still need a way to identify which of the new ensembles to associate them with.\n",
    "\n",
    "There are two main ways to do this. The first is to take one trajectory, and associate it with as many ensembles as possible. If your first path comes from a TPS simulation, that is the approach you'll want to take.\n",
    "\n",
    "The second approach is better suited to our conditions here: we already have a good trajectory for each ensemble. So we just want to remap our old ensembles to new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading one trajectory into lots of ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this makes a dictionary mapping the outermost ensemble of each sampling transition \n",
    "# to a trajectory from the old_sampleset that satisfies that ensemble\n",
    "trajs = {}\n",
    "for ens in [t.ensembles[-1] for t in mstis.sampling_transitions]:\n",
    "    trajs[ens] = [s.trajectory for s in old_sampleset if ens(s.trajectory)][0]\n",
    "    \n",
    "assert(len(trajs)==3) # otherwise, we have a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_samples = {}\n",
    "for t in mstis.sampling_transitions:\n",
    "    initial_samples[t] = paths.SampleSet.map_trajectory_to_ensembles(trajs[t.ensembles[-1]], t.ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replica: 0\n",
      "Trajectory: Trajectory[120]\n",
      "Ensemble: <openpathsampling.ensemble.TISEnsemble object at 0x122c8e850>\n",
      "\n",
      "Replica: 1\n",
      "Trajectory: Trajectory[120]\n",
      "Ensemble: <openpathsampling.ensemble.TISEnsemble object at 0x122ce8410>\n",
      "\n",
      "Replica: 2\n",
      "Trajectory: Trajectory[120]\n",
      "Ensemble: <openpathsampling.ensemble.TISEnsemble object at 0x122ce8f90>\n",
      "\n",
      "Replica: 0\n",
      "Trajectory: Trajectory[65]\n",
      "Ensemble: <openpathsampling.ensemble.TISEnsemble object at 0x122d0a7d0>\n",
      "\n",
      "Replica: 1\n",
      "Trajectory: Trajectory[65]\n",
      "Ensemble: <openpathsampling.ensemble.TISEnsemble object at 0x122d11390>\n",
      "\n",
      "Replica: 2\n",
      "Trajectory: Trajectory[65]\n",
      "Ensemble: <openpathsampling.ensemble.TISEnsemble object at 0x122d11f10>\n",
      "\n",
      "Replica: 0\n",
      "Trajectory: Trajectory[111]\n",
      "Ensemble: <openpathsampling.ensemble.TISEnsemble object at 0x122c72450>\n",
      "\n",
      "Replica: 1\n",
      "Trajectory: Trajectory[111]\n",
      "Ensemble: <openpathsampling.ensemble.TISEnsemble object at 0x1229fa650>\n",
      "\n",
      "Replica: 2\n",
      "Trajectory: Trajectory[111]\n",
      "Ensemble: <openpathsampling.ensemble.TISEnsemble object at 0x122c78190>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for st_idx in range(3):\n",
    "    for s in initial_samples.values()[st_idx]:\n",
    "        print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sset = paths.SampleSet.relabel_replicas_per_ensemble(initial_samples.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sanity_check` function ensures that all trajectories in the sample set are actually in the ensemble they claim to be associated with. At this point, we should have 9 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sset.sanity_check()\n",
    "assert(len(sset)==9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remapping old ensembles to new ensembles\n",
    "\n",
    "If your old and new ensembles have the same string representations, then OPS has a function to help you automatically map them. As long as you create the ensembles in the same way, they'll have the same string representation. Note that if you *don't* have the same string representation, you would have to assign trajectories to ensembles by hand (which isn't that hard, but is a bit tedious)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sset = paths.SampleSet.translate_ensembles(old_sampleset, mstis.sampling_ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sset.sanity_check()\n",
    "assert(len(sset)==9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'face 0\",\n",
       " \"I'face 0\",\n",
       " \"I'face 2\",\n",
       " \"I'face 2\",\n",
       " \"I'face 0\",\n",
       " \"I'face 1\",\n",
       " \"I'face 1\",\n",
       " \"I'face 2\",\n",
       " \"I'face 1\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[samp.ensemble.name for samp in sset.samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up special ensembles\n",
    "\n",
    "Whichever way we initially set up the `SampleSet`, at this point it only contains samples for the main sampling trajectories of each transition. Now we need to put trajectories into various auxiliary ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple state outer ensemble\n",
    "\n",
    "The multiple state outer ensemble is, in fact, sampled during the bootstrapping. However, it is actually sampled once for every state that shares it. It is very easy to find a trajectory that satisfies the ensemble and to load add that sample to our sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for outer_ens in mstis.special_ensembles['ms_outer']:\n",
    "    # doesn't matter which we take, so we take the first\n",
    "    traj = next(s.trajectory for s in old_sampleset if outer_ens(s.trajectory)==True)\n",
    "    samp = paths.Sample(\n",
    "            replica=None,\n",
    "            ensemble=outer_ens,\n",
    "            trajectory=traj\n",
    "    )\n",
    "    # now we apply it and correct for the replica ID\n",
    "    sset.append_as_new_replica(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sset.sanity_check()\n",
    "assert(len(sset)==10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minus interface ensemble\n",
    "\n",
    "The minus interface ensembles do not yet have a trajectory. We will generate them by starting with same-state trajectories (A-to-A, B-to-B, C-to-C) in each interface, and extending into the minus ensemble.\n",
    "\n",
    "* check whether the traj is A-to-A\n",
    "* extend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to make sure that the trajectory in the innermost ensemble of each state also ends in that state. This is necessary so that when we extend the trajectory, it can extends into the minus ensemble.\n",
    "\n",
    "If the trajectory isn't right, we run a shooting move on it until it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for transition in mstis.sampling_transitions:\n",
    "    innermost_ensemble = transition.ensembles[0]\n",
    "    shooter = None\n",
    "    if not transition.stateA(sset[innermost_ensemble].trajectory[-1]):\n",
    "        shooter = paths.OneWayShootingMover(ensemble=innermost_ensemble,\n",
    "                                            selector=paths.UniformSelector(),\n",
    "                                            engine=engine)\n",
    "        pseudoscheme = paths.LockedMoveScheme(root_mover=shooter)\n",
    "        pseudosim = paths.PathSampling(storage=None, \n",
    "                                       move_scheme=pseudoscheme, \n",
    "                                       globalstate=sset,\n",
    "                                      )\n",
    "    while not transition.stateA(sset[innermost_ensemble].trajectory[-1]):\n",
    "        pseudosim.run(1)\n",
    "        sset = pseudosim.globalstate\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the innermost ensembles are safe to use for extending into a minus interface, we extend them into a minus interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minus_samples = []\n",
    "for transition in mstis.sampling_transitions:\n",
    "    minus_samples.append(transition.minus_ensemble.populate_minus_ensemble(\n",
    "        partial_traj=sset[transition.ensembles[0]].trajectory,\n",
    "        minus_replica_id=-len(minus_samples)-1,\n",
    "        engine=engine\n",
    "    ))\n",
    "sset = sset.apply_samples(minus_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sset.sanity_check()\n",
    "assert(len(sset)==13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equilibration\n",
    "\n",
    "In molecular dynamics, you need to equilibrate if you don't start with an equilibrium frame (e.g., if you start with solvent molecules on a grid, your system should equilibrate before you start taking statistics). Similarly, if you start with a set of paths which are far from the path ensemble equilibrium, you need to equilibrate. This could either be because your trajectories are not from the real dynamics (generated with metadynamics, high temperature, etc.) or because your trajectories are not representative of the path ensemble (e.g., if you put transition trajectories into all interfaces).\n",
    "\n",
    "As with MD, running equilibration can be the same process as running the total simulation. However, in path sampling, it doesn't have to be: we can equilibrate without replica exchange moves or path reversal moves, for example. In the example below, we create a `MoveScheme` that only includes shooting movers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "equil_scheme = paths.OneWayShootingMoveScheme(mstis, engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "equilibration = paths.PathSampling(\n",
    "    storage=None,\n",
    "    globalstate=sset,\n",
    "    move_scheme=equil_scheme\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Monte Carlo cycle number 3.\n"
     ]
    }
   ],
   "source": [
    "equilibration.run(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sset = equilibration.globalstate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running RETIS\n",
    "\n",
    "Now we run the full calculation. Up to here, we haven't been storing any of our results. This time, we'll start a storage object, and we'll save the network we've created. Then we'll run a new `PathSampling` calculation object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logging creates ops_output.log file with details of what the calculation is doing\n",
    "#import logging.config\n",
    "#logging.config.fileConfig(\"logging.conf\", disable_existing_loggers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "storage = paths.storage.Storage(\"mstis.nc\", \"w\", use_uuid=old_store.reference_by_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "storage.save(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[cv.with_diskcache(allow_partial=True) for cv in old_store.cvs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mstis_calc = paths.PathSampling(\n",
    "    storage=storage,\n",
    "    globalstate=sset,\n",
    "    move_scheme=paths.DefaultScheme(mstis, engine=engine)\n",
    ")\n",
    "mstis_calc.save_frequency = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block sets up a live visualization. This is optional, and only recommended if you're using OPS interactively (which would only be for very small systems). Some of the same tools can be used to play back the behavior after the fact if you want to see the behavior for more complicated systems. You can create a background (here we use the PES contours), and the visualization will plot the trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! skip\n",
    "# skip this during testing, but leave it for demo purposes\n",
    "from toy_plot_helpers import ToyPlot\n",
    "xval = paths.CV_Function(\"xval\", lambda snap : snap.xyz[0][0])\n",
    "yval = paths.CV_Function(\"yval\", lambda snap : snap.xyz[0][1])\n",
    "mstis_calc.live_visualization = paths.LiveVisualization(mstis, xval, yval, [-1.0, 1.0], [-1.0, 1.0])\n",
    "background = ToyPlot()\n",
    "background.contour_range = np.arange(-1.5, 1.0, 0.1)\n",
    "background.add_pes(engine.pes)\n",
    "mstis_calc.live_visualization.background = background.plot()\n",
    "mstis_calc.visualize_frequency = 1 # increasing this number speeds things up, but isn't as pretty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything is ready: let's run the simulation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mstis_calc.live_visualization = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpos = 0\n",
    "for obj, value in cv._cache_dict.cache.items():\n",
    "    pos = storage.snapshots.pos(obj)\n",
    "    ref = cv._eval_dict[[obj]][0]\n",
    "    \n",
    "    if pos is not None:\n",
    "        dcache = cv._store_dict.value_store.cache.get(pos / 2)\n",
    "        disk = cv._store_dict.value_store.value[pos / 2]\n",
    "    else:\n",
    "        dcache = None\n",
    "        disk = None\n",
    "    if disk and (disk - ref)**2 > 0.00000001:\n",
    "        mpos = max(mpos, pos)\n",
    "        print ref == value, disk == ref, pos, dcache, disk, ref, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mstis_calc.run(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18772 2933\n",
      "18772 2933\n",
      "18772 4454\n",
      "18772 4454\n",
      "18772 7749\n",
      "18772 7749\n",
      "CPU times: user 84 ms, sys: 8.61 ms, total: 92.6 ms\n",
      "Wall time: 86.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for cv in storage.cvs:\n",
    "    vst = cv._store_dict.value_store\n",
    "    print len(storage.snapshots), len(vst)\n",
    "    storage.cvs.sync(cv)\n",
    "    print len(storage.snapshots), len(vst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 18772 2933\n",
      "18772 9386\n",
      "False 18772 4454\n",
      "18772 20505\n",
      "True 18772 7749\n",
      "18772 9386\n",
      "CPU times: user 16.1 s, sys: 176 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for cv in storage.cvs:\n",
    "    vst = cv._store_dict.value_store\n",
    "    print cv.cv_time_reversible, len(storage.snapshots), len(vst)\n",
    "    storage.cvs.complete(cv)\n",
    "    print len(storage.snapshots), len(vst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = storage.snapshots.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 985 ms, sys: 40.5 ms, total: 1.03 s\n",
      "Wall time: 1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = cv(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for snap in storage.snapshots:\n",
    "    ref = cv._eval_dict._get(snap)\n",
    "    cv_val = cv(snap)\n",
    "    if cv_val != ref:\n",
    "        print cv_val, ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# commented out during development, so we can \"run all\" and then do more\n",
    "#storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Monte Carlo cycle number 500.\n",
      "DONE! Completed 500 Monte Carlo cycles.\n"
     ]
    }
   ],
   "source": [
    "mstis_calc.run(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ee = paths.netcdfplus.LoaderProxy(old_store.snapshots, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee in cv._cache_dict.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<openpathsampling.netcdfplus.proxy.LoaderProxy object at 0x1226a1870> True True True\n"
     ]
    }
   ],
   "source": [
    "for s in cv._cache_dict.cache:\n",
    "    if type(s) is paths.netcdfplus.LoaderProxy:\n",
    "        if s._idx == 8:\n",
    "            print s, s._store.content_class is storage.snapshots.content_class, s == ee, hash(s) == hash(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258\n"
     ]
    }
   ],
   "source": [
    "print mpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46928"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(storage.snapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
